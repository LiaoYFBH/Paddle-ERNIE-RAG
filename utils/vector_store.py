import os
import logging
import random
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from ernie_client import ERNIEClient

# é…ç½®æ—¥å¿—
logger = logging.getLogger("vector_store")
logger.setLevel(logging.INFO)

class MilvusVectorStore:
    def __init__(self, uri, token, collection_name, embedding_service_url=None, qianfan_api_key=None):
        self.collection_name = collection_name
        self.uri = uri
        self.token = token
        self.embedding_client = ERNIEClient() 
        self._connect_milvus()
        self._init_collection()

    def _connect_milvus(self):
        try:
            if connections.has_connection("default"):
                logger.info(f"â™»ï¸ æ£€æµ‹åˆ°å·²æœ‰è¿æ¥ï¼Œå¤ç”¨ default è¿æ¥ (URI: {self.uri})")
                return
            
            if self.uri.endswith(".db"):
                logger.info(f"ğŸ“‚ è¿æ¥æœ¬åœ° Milvus Lite: {self.uri}")
                connections.connect("default", uri=self.uri)
            else:
                logger.info(f"ğŸŒ è¿æ¥ Milvus æœåŠ¡å™¨: {self.uri}")
                connections.connect("default", uri=self.uri, token=self.token)
        except Exception as e:
            logger.error(f"âŒ Milvus è¿æ¥å¤±è´¥: {e}")
            if not self.uri.endswith(".db") and not connections.has_connection("default"):
                connections.connect("default", uri="./demo_data.db")

    def _init_collection(self):
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="filename", dtype=DataType.VARCHAR, max_length=256),
            FieldSchema(name="page", dtype=DataType.INT64),
            FieldSchema(name="chunk_id", dtype=DataType.INT64),
            FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=65535),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384)
        ]
        schema = CollectionSchema(fields, "PDF QA Collection")

        if not utility.has_collection(self.collection_name):
            self.collection = Collection(self.collection_name, schema)
            index_params = {
                "metric_type": "L2", 
                "index_type": "FLAT", 
                "params": {} 
            }
            self.collection.create_index(field_name="embedding", index_params=index_params)
            logger.info(f"âœ¨ åˆ›å»ºæ–°é›†åˆ (FLAT ç´¢å¼•): {self.collection_name}")
        else:
            self.collection = Collection(self.collection_name)
            logger.info(f"ğŸ“š åŠ è½½å·²æœ‰é›†åˆ: {self.collection_name}")
        
        self.collection.load()

    def get_embeddings(self, texts):
        if not texts: return []
        try:
            if hasattr(self.embedding_client, 'get_embeddings'):
                return self.embedding_client.get_embeddings(texts)
            else:
                return [self.embedding_client.get_embedding(t) for t in texts]
        except Exception as e:
            logger.error(f"Embedding error: {e}")
            return []

    def _keyword_search(self, query, top_k=50, expr=None):
        """
        å…³é”®è¯æ£€ç´¢ (å¸¦ç®€æ˜“åˆ†è¯/åœç”¨è¯è¿‡æ»¤)
        """
        results = []
        try:
            #  å…³é”®è¯æå–é€»è¾‘
            import re
            # å®šä¹‰è¦å‰”é™¤çš„ï¼šæ ‡ç‚¹ã€ç–‘é—®è¯ã€è™šè¯ã€é€šç”¨åŠ¨è¯
            # (è§£é‡Š|æ˜¯ä»€ä¹ˆ|å«ä¹‰|çš„|ä¸­|æ–‡ç« |å›¾ç‰‡|è¿™ä¸ª|ç¯‡|è¯·é—®|ä»¥åŠ|[\s\?ï¼Ÿ\.,ï¼Œã€‚!ï¼])
            stop_patterns = r"(è§£é‡Š|æ˜¯ä»€ä¹ˆ|å«ä¹‰|çš„|ä¸­|æ–‡ç« |å›¾ç‰‡|è¿™ä¸ª|ç¯‡|è¯·é—®|ä»¥åŠ|[\s\?ï¼Ÿ\.,ï¼Œã€‚!ï¼])"
            
            clean_query = re.sub(stop_patterns, "", query).strip()
            
            final_query = clean_query if len(clean_query) > 0 else query
            
            # print(f"DEBUG: åŸå¥[{query}] -> æå–å…³é”®è¯[{final_query}]") # è°ƒè¯•ç”¨

            keyword_expr = f'content like "%{final_query}%"'
            
            # å¦‚æœå¤–éƒ¨ä¼ æ¥äº† expr (æ¯”å¦‚ filename == 'xxx')ï¼Œéœ€è¦å’Œå…³é”®è¯æ¡ä»¶åˆå¹¶
            if expr:
                final_expr = f"({expr}) and ({keyword_expr})"
            else:
                final_expr = keyword_expr
            
            # æ‰§è¡Œ Milvus æŸ¥è¯¢ ===
            res = self.collection.query(
                expr=final_expr,
                output_fields=["filename", "page", "content", "chunk_id"],
                limit=top_k
            )
            
            # æ ¼å¼åŒ–ç»“æœ ===
            for hit in res:
                results.append({
                    "content": hit.get("content"),
                    "filename": hit.get("filename"),
                    "page": hit.get("page"),
                    "chunk_id": hit.get("chunk_id"),
                    "semantic_score": 0.0,  
                    "raw_score": 100.0,     
                    "type": "keyword",
                    "id": hit.get("id")
                })
        except Exception as e:
            print(f"âš ï¸ å…³é”®è¯æ£€ç´¢è·³è¿‡: {e}")
            
        return results
    def search(self, query: str, top_k: int = 10, **kwargs):
        """
        ã€é«˜ç²¾åº¦æ··åˆæ£€ç´¢ã€‘
        æ–°å¢ **kwargs ä»¥æ¥æ”¶ main_local.py ä¼ æ¥çš„ expr å‚æ•°
        """
        expr = kwargs.get('expr', None)

        # === å‘é‡æ£€ç´¢ (Dense) ===
        dense_results = []
        try:
            query_vector = self.embedding_client.get_embedding(query)
            if query_vector:
                # FLAT ç´¢å¼•ä¸éœ€è¦ nprobe
                search_params = {"metric_type": "L2", "params": {}} 
                
                milvus_res = self.collection.search(
                    data=[query_vector],
                    anns_field="embedding", 
                    param=search_params,
                    limit=top_k * 5,
                    expr=expr, 
                    output_fields=["filename", "page", "content", "chunk_id"]
                )
                
                for hit in milvus_res[0]:
                    # L2è·ç¦»è¶Šå°è¶Šå¥½ï¼Œè½¬æ¢ä¸º 0-100 åˆ†æ•°
                    raw_score = 1.0 / (1.0 + hit.distance) * 100
                    dense_results.append({
                        "content": hit.entity.get("content"),
                        "filename": hit.entity.get("filename"),
                        "page": hit.entity.get("page"),
                        "chunk_id": hit.entity.get("chunk_id"),
                        "semantic_score": hit.distance, 
                        "raw_score": raw_score,
                        "type": "dense",
                        "id": hit.id
                    })
        except Exception as e:
            print(f"âŒ å‘é‡æ£€ç´¢å¼‚å¸¸: {e}")

        # === å…³é”®è¯æ£€ç´¢ (Keyword) ===
        keyword_results = self._keyword_search(query, top_k=top_k * 5, expr=expr)

        # === RRF èåˆ ===
        rank_dict = {}
        
        def apply_rrf(results_list, weight=1.0):
            for rank, item in enumerate(results_list):
                doc_id = item.get('id')
                if not doc_id: 
                    # å¦‚æœæ²¡æœ‰IDï¼Œå°è¯•ç”¨ chunk_id æˆ– å†…å®¹å“ˆå¸Œ
                    doc_id = item.get('chunk_id') or hash(item.get('content'))
                
                if doc_id not in rank_dict:
                    rank_dict[doc_id] = {"data": item, "score": 0.0}
                
                # RRF å…¬å¼
                rank_dict[doc_id]["score"] += weight * (1.0 / (60 + rank))

        apply_rrf(dense_results, weight=1.0)
        apply_rrf(keyword_results, weight=3.0)

        # === æ’åºè¾“å‡º ===
        sorted_docs = sorted(rank_dict.values(), key=lambda x: x['score'], reverse=True)
        final_results = [item['data'] for item in sorted_docs[:top_k * 2]]
        
        print(f"ğŸ” æ··åˆæ£€ç´¢({query}): å‘é‡{len(dense_results)} + å…³é”®è¯{len(keyword_results)} -> èåˆ{len(final_results)}")
        return final_results

    
    def insert_documents(self, documents):
        if not documents: return
        print(f"âš¡ æ­£åœ¨è¯·æ±‚ Embedding (å…± {len(documents)} æ¡)...")
        texts = [doc['content'] for doc in documents]
        
        # è°ƒç”¨ Embedding
        embeddings = self.get_embeddings(texts)

        valid_docs, valid_vectors = [], []
        failed_count = 0
        
        for i, emb in enumerate(embeddings):
            if emb and len(emb) == 384:
                valid_docs.append(documents[i])
                valid_vectors.append(emb)
            else:
                failed_count += 1
        
        if failed_count > 0:
            print(f"âš ï¸ è­¦å‘Š: æœ‰ {failed_count} æ¡ç‰‡æ®µ Embedding å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œæˆ–Keyé—®é¢˜ï¼‰")
            
        if not valid_docs: 
            print("âŒ ä¸¥é‡é”™è¯¯: æ‰€æœ‰ç‰‡æ®µ Embedding å‡å¤±è´¥ï¼Œæ•°æ®æœªå…¥åº“ï¼")
            print("ğŸ‘‰ è¯·æ£€æŸ¥: 1. AISTUDIO_ACCESS_TOKEN æ˜¯å¦æ­£ç¡®/è¿‡æœŸ")
            print("ğŸ‘‰ è¯·æ£€æŸ¥: 2. ç½‘ç»œæ˜¯å¦é€šç•…")
            return

        try:
            data = [
                [doc['filename'] for doc in valid_docs],
                [doc['page'] for doc in valid_docs],
                [doc['chunk_id'] for doc in valid_docs],
                [doc['content'] for doc in valid_docs],
                valid_vectors
            ]
            self.collection.insert(data)
            self.collection.flush() # å¼ºåˆ¶åˆ·ç›˜
            logger.info(f"âœ… æˆåŠŸå…¥åº“: å·²æ’å…¥ {len(valid_vectors)} æ¡æ•°æ®")
        except Exception as e:
            print(f"âŒ Milvus å†™å…¥å¼‚å¸¸: {e}")
    #
    def delete_document(self, filename):
        """
        æ ¹æ®æ–‡ä»¶ååˆ é™¤å‘é‡æ•°æ®
        """
        if not filename: return "âŒ æ–‡ä»¶åä¸ºç©º"
        try:
            # 1. æ‰§è¡Œåˆ é™¤ (ä½¿ç”¨ expr è¡¨è¾¾å¼)
            # æ³¨æ„ï¼šMilvus çš„ delete æ˜¯é€»è¾‘åˆ é™¤
            self.collection.delete(expr=f'filename == "{filename}"')
            
            # 2. å¼ºåˆ¶åˆ·ç›˜ (è®©åˆ é™¤ç«‹å³ç”Ÿæ•ˆ)
            self.collection.flush()
            
            logger.info(f"ğŸ—‘ï¸ å·²ä»åº“ä¸­åˆ é™¤æ–‡æ¡£: {filename}")
            return f"âœ… å·²æˆåŠŸåˆ é™¤: {filename}"
        except Exception as e:
            err_msg = f"âŒ åˆ é™¤å¤±è´¥: {e}"
            logger.error(err_msg)
            return err_msg
    def list_documents(self):
        try:
            res = self.collection.query(expr="id > 0", output_fields=["filename"], limit=16384)
            return sorted(list(set([r['filename'] for r in res])))
        except: return []

    def get_document_content(self, filename):
        try:
            res = self.collection.query(expr=f"filename == '{filename}'", output_fields=["content", "page"], limit=1000)
            res.sort(key=lambda x: x['page'])
            return "\n\n".join([r['content'] for r in res])
        except: return ""

    def test_self_recall(self, sample_size=20):
        """
        è‡ªå›å½’å¬å›æµ‹è¯•ï¼š
        ä»åº“ä¸­éšæœºå– N æ¡æ•°æ®ï¼Œç”¨å®ƒä»¬è‡ªå·±çš„å†…å®¹å»æœï¼Œçœ‹ Top-1 æ˜¯å¦æ˜¯è‡ªå·±ã€‚
        è¯æ˜ FLAT ç´¢å¼•çš„å‡†ç¡®æ€§ã€‚
        """
        try:
            total = self.collection.num_entities
            if total == 0: return "âŒ åº“ä¸ºç©ºï¼Œæ— æ³•æµ‹è¯•"

            limit = min(100, total)
            res = self.collection.query(expr="id > 0", output_fields=["id", "content"], limit=limit)
            
            if not res: return "âŒ æ— æ³•è·å–æ•°æ®"
            
            samples = random.sample(res, min(sample_size, len(res)))
            
            hits = 0
            for item in samples:
                doc_id = item['id']
                content = item['content']
                emb = self.embedding_client.get_embedding(content)
                if not emb: continue
                
                search_res = self.collection.search(
                    data=[emb], 
                    anns_field="embedding", 
                    param={"metric_type": "L2", "params": {}}, # FLATæ— å‚
                    limit=1,
                    output_fields=["id"]
                )
                
                # æ£€æŸ¥ Top-1 ID æ˜¯å¦åŒ¹é…
                if search_res and len(search_res[0]) > 0:
                    top1_id = search_res[0][0].id
                    if top1_id == doc_id:
                        hits += 1
            
            recall_rate = (hits / len(samples)) * 100
            return f"âœ… å¬å›æµ‹è¯• ({len(samples)}æ¡æ ·æœ¬): å‡†ç¡®ç‡ {recall_rate:.1f}%"
            
        except Exception as e:
            return f"âŒ æµ‹è¯•å‡ºé”™: {e}"