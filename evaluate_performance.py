import os
import time
import random
import logging
import pandas as pd
import argparse
from tqdm import tqdm
from dotenv import load_dotenv

from utils.ernie_client import ERNIEClient
from utils.vector_store import MilvusVectorStore
from backend import encode_name

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("evaluator")

# === é…ç½® ===
COLLECTION_UI_NAME = "stx_data"
SAMPLE_NUM = 300
TOP_K_RETRIEVAL = 50
DATASET_PATH = "final_test_dataset.csv"
MAX_CONTENT_LENGTH = 800  # ğŸŒŸ æ–°å¢ï¼šEmbedding å®‰å…¨é•¿åº¦é™åˆ¶

class FinalSaverEvaluator:
    def __init__(self):
        load_dotenv()
        self.llm = ERNIEClient()
        real_name = encode_name(COLLECTION_UI_NAME)
        self.vector_store = MilvusVectorStore(
            uri=os.getenv("MILVUS_URI"),
            token=os.getenv("MILVUS_TOKEN"),
            collection_name=real_name,
            embedding_client=self.llm
        )
        logger.info(f"âœ… è¿æ¥çŸ¥è¯†åº“: {COLLECTION_UI_NAME} | æ ·æœ¬æ•°: {SAMPLE_NUM}")

    def generate_test_dataset(self, num_samples):
        logger.info("ğŸš€ ç”Ÿæˆæµ‹è¯•æ•°æ®é›†...")
        res = self.vector_store.collection.query(
            expr="id > 0", 
            output_fields=["id", "content", "filename", "page"], 
            limit=3000
        )
        if not res: return []
        
        samples = random.sample(res, min(len(res), num_samples + 50))
        test_set = []
        
        for item in tqdm(samples, desc="LLMå‡ºé¢˜"):
            if len(test_set) >= num_samples: break
            content = item['content']
            if len(content) < 60: continue
            
            prompt = f"""Based on the following text snippet, generate a search query in English.
            Snippet: {content[:500]}
            Constraint: Output ONLY the question text in English.
            """
            try:
                question = self.llm.chat([{"role": "user", "content": prompt}])
                if question and "å¤±è´¥" not in question:
                    test_set.append({
                        "question": question,
                        "source_content": content,
                        "target_id": item['id'],
                        "target_filename": item['filename'],
                        "target_page": item['page']
                    })
            except: pass
        return test_set

    def load_existing_dataset(self, path):
        """åŠ è½½å·²æœ‰æ•°æ®é›†"""
        logger.info(f"ğŸ“‚ æ­£åœ¨åŠ è½½å·²æœ‰æ•°æ®é›†: {path}")
        try:
            df = pd.read_csv(path, encoding="utf_8_sig")
            test_set = df.to_dict('records')
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(test_set)} æ¡æµ‹è¯•æ•°æ®")
            return test_set
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return []

    def _truncate_content(self, text: str) -> str:
        """
        ğŸŒŸ æ–°å¢æ–¹æ³•ï¼šæˆªæ–­è¶…é•¿æ–‡æœ¬
        """
        if not text or len(text) <= MAX_CONTENT_LENGTH:
            return text
        
        truncated = text[:MAX_CONTENT_LENGTH]
        
        # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
        last_period = max(
            truncated.rfind('ã€‚'),
            truncated.rfind('.'),
            truncated.rfind('\n')
        )
        
        if last_period > MAX_CONTENT_LENGTH * 0.8:
            truncated = truncated[:last_period + 1]
        
        return truncated

    def _preprocess_dataset(self, test_set: list) -> list:
        """
        ğŸŒŸ æ–°å¢æ–¹æ³•ï¼šé¢„å¤„ç†æ•°æ®é›†ï¼Œæˆªæ–­è¶…é•¿æ–‡æœ¬
        """
        logger.info("ğŸ”§ æ­£åœ¨é¢„å¤„ç†æ•°æ®é›†...")
        truncated_count = 0
        
        for item in test_set:
            original_length = len(item.get('source_content', ''))
            
            # æˆªæ–­ source_content
            if original_length > MAX_CONTENT_LENGTH:
                item['source_content'] = self._truncate_content(item['source_content'])
                truncated_count += 1
        
        if truncated_count > 0:
            logger.warning(f"âš ï¸  å·²æˆªæ–­ {truncated_count} æ¡è¶…é•¿æ–‡æœ¬ (è¶…è¿‡ {MAX_CONTENT_LENGTH} å­—ç¬¦)")
        else:
            logger.info(f"âœ… æ‰€æœ‰æ–‡æœ¬é•¿åº¦å‡åœ¨å®‰å…¨èŒƒå›´å†…")
        
        return test_set

    def run(self, mode="auto"):
        """
        è¿è¡Œè¯„ä¼°
        
        Args:
            mode: 'load' - å¼ºåˆ¶åŠ è½½å·²æœ‰æ•°æ®é›†
                  'generate' - å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
                  'auto' - è‡ªåŠ¨åˆ¤æ–­ï¼ˆæœ‰åˆ™åŠ è½½ï¼Œæ— åˆ™ç”Ÿæˆï¼‰
        """
        # === 1. æ•°æ®é›†å‡†å¤‡ ===
        test_set = []
        
        if mode == "load":
            logger.info("ğŸ“‚ æ¨¡å¼: åŠ è½½å·²æœ‰æ•°æ®é›†")
            test_set = self.load_existing_dataset(DATASET_PATH)
            if not test_set:
                logger.error("âŒ åŠ è½½å¤±è´¥ä¸”æ¨¡å¼ä¸º 'load'ï¼Œé€€å‡ºç¨‹åº")
                return
                
        elif mode == "generate":
            logger.info("ğŸ”„ æ¨¡å¼: å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ•°æ®é›†")
            test_set = self.generate_test_dataset(SAMPLE_NUM)
            if not test_set:
                logger.error("âŒ æ•°æ®é›†ç”Ÿæˆå¤±è´¥")
                return
            
            logger.info(f"ğŸ’¾ æ­£åœ¨ä¿å­˜é¢˜åº“åˆ° {DATASET_PATH} ...")
            df_save = pd.DataFrame(test_set)
            df_save.to_csv(DATASET_PATH, index=False, encoding="utf_8_sig")
            logger.info("âœ… é¢˜åº“ä¿å­˜æˆåŠŸï¼")
            
        else:  # mode == "auto"
            logger.info("ğŸ¤– æ¨¡å¼: è‡ªåŠ¨åˆ¤æ–­")
            if os.path.exists(DATASET_PATH):
                logger.info(f"âœ… æ£€æµ‹åˆ°å·²æœ‰æ•°æ®é›†: {DATASET_PATH}")
                test_set = self.load_existing_dataset(DATASET_PATH)
                
            if not test_set:
                logger.info("âš ï¸  æœªæ‰¾åˆ°æˆ–åŠ è½½å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºç”Ÿæˆæ¨¡å¼")
                test_set = self.generate_test_dataset(SAMPLE_NUM)
                if test_set:
                    df_save = pd.DataFrame(test_set)
                    df_save.to_csv(DATASET_PATH, index=False, encoding="utf_8_sig")
                    logger.info("âœ… é¢˜åº“ä¿å­˜æˆåŠŸï¼")
        
        if not test_set:
            logger.error("âŒ æ— å¯ç”¨æ•°æ®é›†ï¼Œé€€å‡º")
            return
        
        # ğŸŒŸ å…³é”®ä¿®æ”¹ï¼šåœ¨è¯„ä¼°å‰ç»Ÿä¸€é¢„å¤„ç†æ•°æ®é›†
        test_set = self._preprocess_dataset(test_set)
        
        # === 2. å¼€å§‹è¯„æµ‹ ===
        stats = {
            "physical_recall": 0,
            "doc_recall": 0,
            "page_recall": 0,
            "chunk_recall": 0
        }
        
        logger.info(f"ğŸš€ å¼€å§‹å…¨é“¾è·¯è¯„ä¼°...")
        
        for item in tqdm(test_set, desc="è¯„ä¼°ä¸­"):
            # === æµ‹è¯• 1: (å‘é‡æœå‘é‡) ===
            try:
                content_emb = self.vector_store.embedding_client.get_embedding(item['source_content'])
                res_phy = self.vector_store.collection.search(
                    data=[content_emb], anns_field="embedding", param={"metric_type": "L2", "params": {}}, 
                    limit=TOP_K_RETRIEVAL, output_fields=["id"]
                )
                ids_phy = [h.id for h in res_phy[0]]
                if item['target_id'] in ids_phy:
                    stats['physical_recall'] += 1
            except: pass

            # === æµ‹è¯• 2: çœŸå® QA æ£€ç´¢ (Hybrid Search) ===
            try:
                results = self.vector_store.search(item['question'], top_k=TOP_K_RETRIEVAL)
                
                # A. æ–‡æ¡£çº§
                filenames = [r.get('filename') for r in results]
                if item['target_filename'] in filenames:
                    stats['doc_recall'] += 1
                    
                    # B. é¡µçº§
                    for r in results:
                        if r.get('filename') == item['target_filename'] and r.get('page') == item['target_page']:
                            stats['page_recall'] += 1
                            break
                
                # C. åˆ‡ç‰‡çº§
                ids = [r.get('id') for r in results]
                if item['target_id'] in ids:
                    stats['chunk_recall'] += 1
            except: pass
            
        # === è¾“å‡ºç»“æœ ===
        total = len(test_set)
        def get_pct(k): return (stats[k] / total) * 100
        
        print("\n" + "="*80)
        print("ğŸ“Š ç³»ç»Ÿæ€§èƒ½å…¨æ™¯å›¾ (System Performance Panorama)")
        print("="*80)
        print(f"{'Metric Layer':<25} | {'hit rate@50':<10} | {'Interpretation'}")
        print("-" * 80)
        print(f"{'1. Vector Self-Recall':<25} | {get_pct('physical_recall'):6.2f}%    | åŸæ–‡æ£€ç´¢åŸæ–‡")
        print("-" * 80)
        print(f"{'2. Document Recall':<25} | {get_pct('doc_recall'):6.2f}%    | å®è§‚å®šä½")
        print(f"{'3. Page Recall':<25} | {get_pct('page_recall'):6.2f}%    | ä¸­è§‚å®šä½")
        print(f"{'4. Chunk Recall':<25} | {get_pct('chunk_recall'):6.2f}%    | å¾®è§‚å®šä½")
        print("="*80)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PDF QA ç³»ç»Ÿæ€§èƒ½è¯„ä¼°å·¥å…·")
    parser.add_argument(
        "--mode", 
        type=str, 
        choices=["load", "generate", "auto"], 
        default="auto",
        help="æ•°æ®é›†æ¨¡å¼: load=åŠ è½½å·²æœ‰ | generate=é‡æ–°ç”Ÿæˆ | auto=è‡ªåŠ¨åˆ¤æ–­(é»˜è®¤)"
    )
    
    args = parser.parse_args()
    
    eval = FinalSaverEvaluator()
    eval.run(mode=args.mode)